# 新实验考虑

## 论文查看

+ [ ] SDTF-Net 提取的静态、动态的时频特征？需要理解 （没有源码，复现模型难度中等）
+ [x] 159 多CNN 中文
	+ 没有源码，模型复现难度小，数据预处理部分有待深究
	+ 可参考实验做法，实验较为细致，且做了大量不同参数下的比较
	+ 实验结果可对比，高出了不少
	+ 想法：2D 不同模型，不同特征图，可以进行比较；1D 和 3D 都有强调时序，改用LSTM或Transforms是一个方向
+ [ ] 117 CNN+LSTM 传统 大量数据集对比
	+ 该论文较难，不明白什么是 CapsNet
	+ 有提到一下最好的特征 MFCC delta-delta？用得都不是中文的数据集
+ [ ] 45 相位？ 幅度？
+ [x] 138 类别不平衡，符合本数据集情况
	+ 这个损失函数可以用，消融实验里和Softmax做对比
+ [ ] 84 选特征的方法？做特征选择的实验应该有用
	+ 没看懂这个特征选择方法，也没看到鹿群优化算法
+ [ ] 6 LSTM+Transform
	+ 复现简单，可以考虑用他的模型结构来在MFCC上识别时序特征

+ Focal Loss
	+ https://zhuanlan.zhihu.com/p/68786098

## 论文使用的一些语料

- 现有研究证明，基于CNN的模型在静态局部特征提取中是优越的（Mao et al.，2014；Fayek et al.，2017；Abdul-Cayyum et al.，2019；Anvarjon et al.，2020）
- 然而，这种基于2D细胞神经网络的方法使用2D时间-频率谱图作为细胞神经网络学习特征表示的输入。因此，它们无法捕捉话语中连续帧的2D时间-频率表示的变化，从而无法获得足够的SER判别特征。`159`
- LSTM架构拥有对时间序列进行建模能力，但对语音情感中的长期依赖关系仍有不足；`6->13`
- 图4双路模型的左侧是一个基于LSTM+Transformer的语音情感识别模块 `6`
- 焦点损失通过重塑交叉熵损失函数来实现这一点，减少对简单例子的重视，更多地关注困难的例子。
- Focal Loss是Softmax Loss的动态缩放版本，它将训练集中在稀疏的硬示例集上，同时防止大量简单示例对系统的影响。
