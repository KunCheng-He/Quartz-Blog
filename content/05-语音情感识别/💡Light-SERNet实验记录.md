# 1. Light-SERNet

## 1.1 声谱图

+ 07-31-14-17
	+ dropout: 0.0
	+ lr: 1e-5
	+ valid_rate: 0.1

| 正向 | 中性 | 负向 |
|:----:|:----:|:----:|
| 1550 | 393  |  0   |
| 834  | 1311 |  0   |
| 101  | 305  |  0   |

总体 ACC： 0.637      各类别 ACC：0.624  0.653  0.0
各类别召回率：0.798  0.611  0.0              各类别F1：0.700  0.631  0.0

---

>上面一次是第一次开始做类别乱序，这里开始做类别均衡

+ 07-31-21-01
	+ dropout: 0.0
	+ lr: 1e-4
	+ valid_rate: 0.1

| 正向 | 中性 | 负向 |
|:----:|:----:|:----:|
| 1255 | 237  | 451  |
| 744  | 637  | 764  |
|  32  |  32  | 342  |

总体 ACC： 0.497      各类别 ACC：0.618  0.703  0.220
各类别召回率：0.646  0.297  0.842              各类别F1：0.632  0.418  0.348

+ 08-01-10-41
	+ dropout：0.0
	+ lr：1e-3
	+ valid：0.15

总体效果和上面差不多

+ 🚩🚩🚩08-01-11-52
	+ dropout: 0.2
	+ lr: 1e-5
	+ valid: 0.15

| 正向 | 中性 | 负向 |
|:----:|:----:|:----:|
| 1280 | 445  | 218  |
| 679  | 1047  | 419  |
|  46  |  97  | 263  |

总体 ACC： 0.576      各类别 ACC：0.638  0.659  0.292
各类别召回率：0.659  0.488  0.648              各类别F1：0.648  0.561  0.403

---

> 这里开始仅保留低频有信息的部分

+ 08-01-16-28
	+ dropout: 0.2
	+ lr: 1e-5
	+ valid: 0.15

主要是去除了高频多余的部分，只保留低频内容，效果在负向上提升显著，其他两个类别反而降低了，而且loss下降曲线很奇怪

+ 08-01-17-20
	+ lr: 1e-4

其余没变，效果依然不怎么好

---

> 这里开始保留所有 epoch 的模型

+ 08-02-10-38
	+ lr: 1e-6

调小学习率之后训练集和验证集的loss下降确实抖动小了很多，但是下降缓慢，500个epoch跑完也没有得到比之前好的效果，所以认为 `1e-5` 仍然是一个较为合适的学习率，下面重跑一遍该学习率，和之前的区别在于保存所有 epoch 的模型参数

+ 08-02-15-12
	+ lr: 1e-5

比较特别的点，学习率没有下降过，训练集的loss还在线性下降，消极类别的正确率提高了（减小了误分率），但正类的正确率较低，大部分分为中性，因为学习率没有下降，所以模型导入之前的参数，接着训练

+ 08-02-20-11
	+ lr: 1e-5

因为是接着上一次训练，最后的结果，用的 epoch-489.pth，发现过拟合了，所以之前的情况也是过拟合造成的，**往前面选应该有更理想的结果**（经过实验室，往前面选之后，大部分类别也是集中在中性这个类别，模型往后的学习过程中，学会分的是负向这个类别，但正向这个类别并没有学到太多东西，我最后再用 1e-5这个学习率重新跑一遍）

+ 08-03-09-36
	+ lr: 1e-5

保持学习率再跑了一遍，通过看图发现，效果和之前是保留高频时是差不多的，且除去高频后，验证集的loss抖动一直是一个谜，怎么调整学习率都没有（师兄提醒这是过拟合的问题），但这抖动从训练的很早开始就有了。所以回到保留高频时训练，通过调整batch_size来看一下实验效果

---

+ 08-03-15-03
	+ lr: 1e-5
	+ batch_size: 8

| 正向 | 中性 | 负向 |
|:----:|:----:|:----:|
| 1684 | 100  | 159  |
| 1337  | 407  | 401  |
|  52  |  2  | 352  |

总体 ACC： 0.544      各类别 ACC：0.548  0.799  0.386
各类别召回率：0.867  0.19  0.867              各类别F1：0.671  0.307  0.534

回到保留高频部分，只是调小了batch_size，验证集的loss下降抖动较大；不知道什么原因，我将batch_size改回16之后再跑一下

+ 08-04-09-30
	+ lr: 1e-5
	+ batch_size: 16

| 正向 | 中性 | 负向 |
|:----:|:----:|:----:|
| 1100 | 556  | 287  |
| 472  | 1208  | 465  |
|  25  |  35  | 346  |

| 正向 | 中性 | 负向 |
|:----:|:----:|:----:|
| **56.6** | 28.6  | 14.8  |
| 22  | **56.3**  | 21.7  |
|  6.2  |  8.6  | **85.2**  |


总体 ACC： 0.591      各类别精确率：0.689  0.671  0.315
各类别召回率：0.566  0.563  0.852              各类别F1：0.621  0.613  0.460

离谱，我改回来以后，这个曲线和上次跑的完全不一样，验证集在抖，训练集在降，调大学习率再试一下

## 1.2 MFCC

---
<center>📌📌📌09-18📌📌📌</center>

| batch | epoch | lr   | 类别平衡 | Loss  |     |
| ----- | ----- | ---- | ---- | ----- | --- |
| 16    | 500   | 1e-4 | True | Cross |     |
+ epoch-94
                   precision    recall  f1-score   support
          正向       0.64      0.76      0.69      1943
          正常       0.77      0.48      0.59      2145
          负向       0.45      0.94      0.61       406

    accuracy                                  0.64      4494
   macro avg       0.62      0.73      0.63      4494
weighted avg       0.68      0.64      0.63      4494

|  正向  |  正常  | 负向  |
|:------:|:------:|:-----:|
| `1470` |  301   |  172  |
|  828   | `1021` |  296  |
|   15   |   8    | `383` |

---

| batch | epoch | lr   | 类别平衡 | Loss  |
| ----- | ----- | ---- | -------- | ----- |
| 16    | 500   | 1e-5 | True     | Cross | 
和上面差不多，没有上面高，0.61 左右

---

| batch | epoch | lr   | 类别平衡  | Loss  |     |
| ----- | ----- | ---- | ----- | ----- | --- |
| 16    | 500   | 1e-4 | False | Cross |     |
+ epoch-422
                  precision    recall  f1-score   support
          正向       0.95      0.95      0.95      1943
          正常       0.94      0.95      0.95      2145
          负向       0.94      0.90      0.92       406

    accuracy                                  0.95      4494
   macro avg       0.95      0.93      0.94      4494
weighted avg       0.95      0.95      0.95      4494

|   正向   |   正常   |  负向   |
| :----: | :----: | :---: |
| `1850` |   90   |   3   |
|   84   | `2041` |  20   |
|   9    |   32   | `365` |
+ epoch-248
                  precision    recall  f1-score   support
          正向       0.92      0.95      0.93      1943
          正常       0.82      0.96      0.89      2145
          负向       0.00      0.00      0.00       406

    accuracy                                  0.87      4494
   macro avg       0.58      0.64      0.61      4494
weighted avg       **0.79**      0.87      0.83      4494

|  正向  |  正常  | 负向 |
|:------:|:------:|:----:|
| `1838` |  105   |  0   |
|   86   | `2059` |  0   |
|   74   |  `332`   |  0   |

---

| batch | epoch | lr   | 类别平衡  | Loss  |     |
| ----- | ----- | ---- | ----- | ----- | --- |
| 16    | 500   | 1e-4 | False | Focal |     |
+ epoch-496
                       precision    recall  f1-score   support
          正向       0.93      0.96      0.94      1943
          正常       0.94      0.94      0.94      2145
          负向       0.94      0.84      0.89       406

    accuracy                                  0.94      4494
   macro avg       0.94      0.91      0.92      4494
weighted avg       **0.94**      0.94      0.94      4494

|  正向  |  正常  | 负向 |
|:------:|:------:|:----:|
| `1857` |   84   |  2   |
|  116   | `2011` |  18  |
|   25   |   39   |  `342`   |



